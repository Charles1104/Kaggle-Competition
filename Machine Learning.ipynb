{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/charles/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time, datetime\n",
    "import data_wrangling as dw\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import chi2, SelectKBest, f_classif\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_mask(df, key = 'Proc.Start.Date', value = '01/01/08'):\n",
    "    t = time.mktime(datetime.datetime.strptime(value,'%d/%m/%y').timetuple())\n",
    "    return df[key] >= t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_df(df):\n",
    "    mask = time_mask(df)\n",
    "    \n",
    "    finalDf_train = df[-mask]\n",
    "    finalDf_test = df[mask]\n",
    "\n",
    "    #creating X, y splits for test and train dataframes\n",
    "    y_train = finalDf_train['Grant.Status'].values\n",
    "    del finalDf_train['Grant.Status']\n",
    "    del finalDf_train['Start.date']\n",
    "    X_train = finalDf_train.values\n",
    "\n",
    "    y_test = finalDf_test['Grant.Status'].values\n",
    "    del finalDf_test['Grant.Status']\n",
    "    del finalDf_test['Start.date']\n",
    "    X_test = finalDf_test.values\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, finalDf_test, finalDf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2821: DtypeWarning: Columns (90,105,119,120,123,124,132,134,135,138,139,147,149,150,153,154,162,164,165,168,169,177,179,183,184,192,194,198,199,207,209,213,214,224,237,239,244) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "orig = dw.get_tables()\n",
    "munged = dw.munge_data(orig)\n",
    "X_train, y_train, X_test, y_test, finalDf_test, finalDf_train = split_df(munged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(X, y, X_holdout = None, y_holdout = None, a = None):\n",
    "    if(a != None):\n",
    "        train_labels = np.arange(X.shape[0])\n",
    "        test_labels = np.arange(X_holdout.shape[0]) + X.shape[0]\n",
    "        X = np.concatenate((X, X_holdout), axis = 0)\n",
    "        y = np.concatenate((y, y_holdout), axis = 0)\n",
    "        cv_custom = [(train_labels, test_labels)]\n",
    "    estimators = [\n",
    "            ('scale_predictors', StandardScaler()),\n",
    "            #('feature_selector', LinearSVC(penalty='l1', dual=False)),\n",
    "            #('feature_selector', SelectKBest(score_func=f_classif)),\n",
    "            #('linearSVC', LinearSVC())\n",
    "            ('randomforests', RandomForestClassifier())\n",
    "            ]\n",
    "    clf = Pipeline(estimators)\n",
    "    params = dict(\n",
    "            #linearSVC__C=[0.1, 1, 10],\n",
    "            randomforests__max_depth=[5, 10, None], \n",
    "            randomforests__n_estimators=[10, 50, 100,1000,10000], \n",
    "            #feature_selector__C=[0.1, 1, 10]\n",
    "            #feature_selector__score_func=[chi2],\n",
    "            #feature_selector__k=[5, 10, 'all'] \n",
    "            )\n",
    "    if(a != None):\n",
    "        grid_search = GridSearchCV(clf, param_grid=params, cv=cv_custom, scoring = 'roc_auc', n_jobs = 6)\n",
    "    else:\n",
    "        grid_search = GridSearchCV(clf, param_grid=params, scoring = 'roc_auc', n_jobs = 6)\n",
    "    grid_search.fit(X, y)\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performance(results, param1, param2):\n",
    "    param1_vals = [x.parameters[param1] for x in results.grid_scores_]\n",
    "    param2_vals = [x.parameters[param2] for x in results.grid_scores_]\n",
    "    means = [x.mean_validation_score for x in results.grid_scores_]\n",
    "    df = pd.DataFrame(list(zip(param1_vals, param2_vals, means)), columns = [param1, param2, 'means'])\n",
    "    df.fillna('None', inplace=True)\n",
    "    return pd.pivot_table(df, values = 'means' , index = param1, columns = param2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%pylab\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.close('all')\n",
    "pylab.rcParams['figure.figsize'] = (30.0, 30.0)\n",
    "\n",
    "offset = 12*0\n",
    "n = 24\n",
    "cols = 3\n",
    "myrange = finalDf_train.columns[list(range(6))+list(range(10, 14))+list(range(15, 20))+[37, 38, 42, 58, 63, 68, 69, 70, 76]]\n",
    "fig, sbp = plt.subplots(n//cols, cols)\n",
    "fig.tight_layout()\n",
    "for i, l in enumerate(myrange[offset:offset+n]):\n",
    "    #print(i,l)\n",
    "    sbp[i //cols][i % cols].set_title('{}: '.format(i+offset)+l, size=30)\n",
    "    finalDf_train[l].hist(ax=sbp[i //cols ][i % cols], bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomforests__n_estimators     10        50        100       1000      10000\n",
      "randomforests__max_depth                                                     \n",
      "5.0                          0.828633  0.854014  0.870623  0.881781  0.879510\n",
      "10.0                         0.852909  0.886942  0.887675  0.895702  0.894369\n",
      "None                         0.846546  0.879259  0.881840  0.889541  0.889702\n",
      "randomforests__n_estimators     10        50        100       1000      10000\n",
      "randomforests__max_depth                                                     \n",
      "5.0                          0.849572  0.886786  0.888438  0.885124  0.887149\n",
      "10.0                         0.868093  0.900456  0.897179  0.909500  0.910132\n",
      "None                         0.823304  0.900249  0.909848  0.910488  0.910219\n"
     ]
    }
   ],
   "source": [
    "model_on_train = testing(X_train, y_train)\n",
    "model_on_test = testing(X_train, y_train, X_holdout=X_test, y_holdout=y_test, a = 2)\n",
    "model_on_train.best_score_\n",
    "model_on_test.best_score_\n",
    "a = list(model_on_train.param_grid)\n",
    "train_results = performance(model_on_train, a[0],  a[1])\n",
    "a = list(model_on_test.param_grid)\n",
    "test_results = performance(model_on_test, a[0],  a[1])\n",
    "print(train_results)\n",
    "print(test_results)\n",
    "# can only take 2 variables for our pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
