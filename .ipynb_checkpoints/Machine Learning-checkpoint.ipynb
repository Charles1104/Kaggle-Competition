{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time, datetime\n",
    "import data_wrangling as dw\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import chi2, SelectKBest, f_classif\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_mask(df, key = 'Proc.Start.Date', value = '01/01/08'):\n",
    "    t = time.mktime(datetime.datetime.strptime(value,'%d/%m/%y').timetuple())\n",
    "    return df[key] >= t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_df(df):\n",
    "    mask = time_mask(df)\n",
    "    \n",
    "    finalDf_train = df[-mask]\n",
    "    finalDf_test = df[mask]\n",
    "\n",
    "    #creating X, y splits for test and train dataframes\n",
    "    y_train = finalDf_train['Grant.Status'].values\n",
    "    del finalDf_train['Grant.Status']\n",
    "    del finalDf_train['Start.date']\n",
    "    X_train = finalDf_train.values\n",
    "\n",
    "    y_test = finalDf_test['Grant.Status'].values\n",
    "    del finalDf_test['Grant.Status']\n",
    "    del finalDf_test['Start.date']\n",
    "    X_test = finalDf_test.values\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, finalDf_test, finalDf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2821: DtypeWarning: Columns (90,105,119,120,123,124,132,134,135,138,139,147,149,150,153,154,162,164,165,168,169,177,179,183,184,192,194,198,199,207,209,213,214,224,237,239,244) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n",
      "/home/charles/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2881: DtypeWarning: Columns (90,105,119,120,123,124,132,134,135,138,139,147,149,150,153,154,162,164,165,168,169,177,179,183,184,192,194,198,199,207,209,213,214,224,237,239,244) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/home/charles/Desktop/DSR/mini-competition/data_wrangling2.py:63: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  x[i] = 2017 - (np.nansum(tmp_df3.iloc[i, :]) / (16 - nan_ctr))\n"
     ]
    }
   ],
   "source": [
    "orig = dw.get_tables()\n",
    "munged = dw.munge_data(orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "munged[\"AvAge\"].fillna(munged[\"AvAge\"].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, finalDf_test, finalDf_train = split_df(munged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(X, y, X_holdout = None, y_holdout = None, a = None):\n",
    "    if(a != None):\n",
    "        train_labels = np.arange(X.shape[0])\n",
    "        test_labels = np.arange(X_holdout.shape[0]) + X.shape[0]\n",
    "        X = np.concatenate((X, X_holdout), axis = 0)\n",
    "        y = np.concatenate((y, y_holdout), axis = 0)\n",
    "        cv_custom = [(train_labels, test_labels)]\n",
    "    estimators = [\n",
    "            #('scale_predictors', StandardScaler()),\n",
    "            #('feature_selector', LinearSVC(penalty='l1', dual=False)),\n",
    "            #('feature_selector', SelectKBest(score_func=f_classif)),\n",
    "            #('linearSVC', LinearSVC())\n",
    "            ('randomforests', RandomForestClassifier())\n",
    "            ]\n",
    "    clf = Pipeline(estimators)\n",
    "    params = dict(\n",
    "            #linearSVC__C=[0.1, 1, 10],\n",
    "            randomforests__max_depth=[5, 10, None], \n",
    "            randomforests__n_estimators=[10, 50, 100,1000], \n",
    "            #feature_selector__C=[0.1, 1, 10]\n",
    "            #feature_selector__score_func=[chi2],\n",
    "            #feature_selector__k=[5, 10, 'all'] \n",
    "            )\n",
    "    if(a != None):\n",
    "        grid_search = GridSearchCV(clf, param_grid=params, cv=cv_custom, scoring = 'roc_auc', n_jobs = 6)\n",
    "    else:\n",
    "        grid_search = GridSearchCV(clf, param_grid=params, scoring = 'roc_auc', n_jobs = 6)\n",
    "    grid_search.fit(X, y)\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performance(results, param1, param2):\n",
    "    param1_vals = [x.parameters[param1] for x in results.grid_scores_]\n",
    "    param2_vals = [x.parameters[param2] for x in results.grid_scores_]\n",
    "    means = [x.mean_validation_score for x in results.grid_scores_]\n",
    "    df = pd.DataFrame(list(zip(param1_vals, param2_vals, means)), columns = [param1, param2, 'means'])\n",
    "    df.fillna('None', inplace=True)\n",
    "    return pd.pivot_table(df, values = 'means' , index = param1, columns = param2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%pylab\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.close('all')\n",
    "pylab.rcParams['figure.figsize'] = (30.0, 30.0)\n",
    "\n",
    "offset = 12*0\n",
    "n = 24\n",
    "cols = 3\n",
    "myrange = finalDf_train.columns[list(range(6))+list(range(10, 14))+list(range(15, 20))+[37, 38, 42, 58, 63, 68, 69, 70, 76]]\n",
    "fig, sbp = plt.subplots(n//cols, cols)\n",
    "fig.tight_layout()\n",
    "for i, l in enumerate(myrange[offset:offset+n]):\n",
    "    #print(i,l)\n",
    "    sbp[i //cols][i % cols].set_title('{}: '.format(i+offset)+l, size=30)\n",
    "    finalDf_train[l].hist(ax=sbp[i //cols ][i % cols], bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomforests__n_estimators     10        50        100       1000      10000\n",
      "randomforests__max_depth                                                     \n",
      "5.0                          0.828021  0.863340  0.876222  0.878667  0.880853\n",
      "10.0                         0.844426  0.881101  0.890191  0.895460  0.894414\n",
      "None                         0.837613  0.860987  0.885129  0.889548  0.889414\n",
      "randomforests__n_estimators     10        50        100       1000      10000\n",
      "randomforests__max_depth                                                     \n",
      "5.0                          0.836869  0.878235  0.880428  0.886565  0.889147\n",
      "10.0                         0.887981  0.905108  0.906916  0.909498  0.910346\n",
      "None                         0.841115  0.890540  0.905423  0.909642  0.910576\n"
     ]
    }
   ],
   "source": [
    "model_on_train = testing(X_train, y_train)\n",
    "model_on_test = testing(X_train, y_train, X_holdout=X_test, y_holdout=y_test, a = 2)\n",
    "model_on_train.best_score_\n",
    "model_on_test.best_score_\n",
    "a = list(model_on_train.param_grid)\n",
    "train_results = performance(model_on_train, a[0],  a[1])\n",
    "a = list(model_on_test.param_grid)\n",
    "test_results = performance(model_on_test, a[0],  a[1])\n",
    "print(train_results)\n",
    "print(test_results)\n",
    "# can only take 2 variables for our pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
