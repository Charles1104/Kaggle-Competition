{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tables(filename = 'data/unimelb_training.csv'):\n",
    "    df_raw = pd.read_csv(filename)\n",
    "    #delete the last column which has only Nan\n",
    "    del df_raw[df_raw.columns[-1]]\n",
    "    #extract the first 26 columns that are the non-repeated columns to each application\n",
    "    df_grants = df_raw[df_raw.columns[:26]]\n",
    "    #Create an array with 15 entries containing each a dataframe with 41 columns\n",
    "    researcher_columns = [df_raw[list(df_raw.columns[0:26]) + list(df_raw.columns[26 + 15*i : 26 + 15 * (i+1)])] for i in range(int(len(df_raw.columns[26:])/15))]\n",
    "    #put the same column name to each entries in the researcher columns\n",
    "    for table in researcher_columns:\n",
    "        table.columns = [list(df_raw.columns[0:26]) + list(researcher_columns[0].columns[26:])]\n",
    "    # Concatenate the array of each entries in the researcher_columns into one big dataframe\n",
    "    researchers = pd.concat(researcher_columns)\n",
    "    #drop duplicate - repeated missing candidates per team\n",
    "    unique_researchers = researchers.drop_duplicates()\n",
    "    #return the dataframe sorted by \"application ID\"\n",
    "    return unique_researchers.sort_values('Grant.Application.ID') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create dummy variable columns for SEO and RFCD\n",
    "def combine_columns(dfOrig, codeName = 'SEO.Code.', prcName = 'SEO.Percentage.', codeRange = 5, index = 'Grant.Application.ID'):\n",
    "    \"\"\" Goes through all codeNames + codeRange, , impute '99' to blanks, get_dummies on them, drops colums with code 0 and\n",
    "    add up each throughout the range.\"\"\"\n",
    "    #get a copy of the original dataframe\n",
    "    df = dfOrig.copy()\n",
    "    #create a dataframe cleanDF that will get five columns for the SEO code\n",
    "    cleanDf = df[['{}{}'.format(codeName, i) for i in range(1, codeRange+1)]].fillna(990000) // 10000\n",
    "    cleanDf[index] = df[index]\n",
    "    dummyDf = []\n",
    "    for i in range(1, codeRange + 1):\n",
    "        #add to cleanDf the columns SEO percentage\n",
    "        cleanDf['{}{}'.format(prcName, i)] = df['{}{}'.format(prcName, i)]\n",
    "        #create 'currDummy' dataframe that will have the SEO columns from cleanDF\n",
    "        currDummy = cleanDf[[index] + ['{}{}'.format(codeName, i)]]\n",
    "        #create dummies from the SEO columns\n",
    "        currDummy = pd.get_dummies(currDummy['{}{}'.format(codeName, i)], prefix = codeName)\n",
    "        #add the 'Grant.Application.ID' column to currDummy \n",
    "        currDummy[index] = cleanDf[index]\n",
    "        #add the percentage column\n",
    "        currDummy['{}{}'.format(prcName, i)] = cleanDf['{}{}'.format(prcName, i)]\n",
    "        #groupby the 'Grant.Application.ID'\n",
    "        currDummy = currDummy.groupby(index)[currDummy.columns].max()\n",
    "        #Create a new DF \"currDUmmy2\" and multiply each individual cell by its percentage\n",
    "        currDummy2 = currDummy.apply(lambda x: x[:-2] * x[-1], axis = 1)\n",
    "        currDummy2[index] = currDummy[index]\n",
    "        #Append currDummy2 to a list - after the for loop ends, there will be five entries in this list\n",
    "        dummyDf.append(currDummy2)\n",
    "    currDummy = dummyDf[0]\n",
    "    #Concatenate each entry in the list into a big dataframe\n",
    "    for i in range(1, codeRange):\n",
    "        currDummy = currDummy.add(dummyDf[i], fill_value = 0.)\n",
    "        currDummy[index] = dummyDf[i][index]\n",
    "        currDummy.fillna(0, inplace=True)\n",
    "    return currDummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def munge_data(df_orig):\n",
    "    df = df_orig.copy()\n",
    "    \n",
    "    #Remove the Person-ID this information is useless\n",
    "    del df['Person.ID.1']\n",
    "    \n",
    "    # Create oldest DF where applications are grouped and only year of birth column is kept with its min value for each team\n",
    "    oldest = pd.DataFrame(df.groupby('Grant.Application.ID')['Year.of.Birth.1'].min())\n",
    "\n",
    "    # Create a numRole DF and get the number of researchers for each role. Groupby application ID\n",
    "    numRole = pd.get_dummies(df['Role.1'])\n",
    "    numRole['Grant.Application.ID'] = df['Grant.Application.ID']\n",
    "    numRole = numRole.groupby('Grant.Application.ID')[numRole.columns].sum()\n",
    "\n",
    "    # Create a numAussies DF and get the % of aussies per application ID\n",
    "    numAussies = pd.get_dummies(df['Country.of.Birth.1'])\n",
    "    numAussies.set_index(df['Grant.Application.ID'], inplace = True)\n",
    "    numAussies = numAussies.groupby('Grant.Application.ID')[numAussies.columns].sum()\n",
    "\n",
    "    # Create a prcAussies DF + imput all values with NaN (no country info) to zero\n",
    "    prcAussies = pd.DataFrame((numAussies['Australia'] / numAussies.sum(axis = 1)).fillna(0), columns = ['% Australians'])\n",
    "\n",
    "    # Create a numPapers DF with the sum of the # of published papers per team\n",
    "    numPapers = df.groupby('Grant.Application.ID')['A..1', 'A.1','B.1', 'C.1','Number.of.Successful.Grant.1','Number.of.Unsuccessful.Grant.1'].sum()\n",
    "\n",
    "    # Replace all the missing values in the 'Contract.Value.Band...see.note.A' by 'A' (the mode value)\n",
    "    df['Contract.Value.Band...see.note.A'].fillna('A', inplace=True)\n",
    "    # Remove all the white space in the 'Contract.Value.Band...see.note.A' column and replace the letter by their ASCII numerical code\n",
    "    df['Contract.Value.Band...see.note.A']=df['Contract.Value.Band...see.note.A'].apply(lambda x: ord(x.rstrip(' ')))\n",
    "\n",
    "    # Create a 'grant_cats' DF converting categories to dummy variables\n",
    "    grant_cats = pd.get_dummies(df['Grant.Category.Code'], dummy_na=True)    \n",
    "    grant_cats['Grant.Application.ID']=df['Grant.Application.ID']\n",
    "    grant_cats = grant_cats.groupby('Grant.Application.ID')[grant_cats.columns].min()  \n",
    "    grant_cats = pd.DataFrame(grant_cats)\n",
    "\n",
    "    # imputing missing percentages for RFCD.Percentage columns with the mean\n",
    "    df['RFCD.Percentage.1'].fillna(df['RFCD.Percentage.1'].mean(), inplace=True)\n",
    "    df['RFCD.Percentage.2'].fillna(df['RFCD.Percentage.2'].mean(), inplace=True)\n",
    "    df['RFCD.Percentage.3'].fillna(df['RFCD.Percentage.3'].mean(), inplace=True)\n",
    "    df['RFCD.Percentage.4'].fillna(df['RFCD.Percentage.4'].mean(), inplace=True)\n",
    "    df['RFCD.Percentage.5'].fillna(df['RFCD.Percentage.5'].mean(), inplace=True)\n",
    "\n",
    "    # doing the same as above with SEO.Percentage columns\n",
    "    df['SEO.Percentage.1'].fillna(df['SEO.Percentage.1'].mean(), inplace=True)\n",
    "    df['SEO.Percentage.2'].fillna(df['SEO.Percentage.2'].mean(), inplace=True)\n",
    "    df['SEO.Percentage.3'].fillna(df['SEO.Percentage.3'].mean(), inplace=True)\n",
    "    df['SEO.Percentage.4'].fillna(df['SEO.Percentage.4'].mean(), inplace=True)\n",
    "    df['SEO.Percentage.5'].fillna(df['SEO.Percentage.5'].mean(), inplace=True)\n",
    "    \n",
    "    rfcds = combine_columns(df, 'RFCD.Code.', 'RFCD.Percentage.')\n",
    "    seos = combine_columns(df, 'SEO.Code.', 'SEO.Percentage.')\n",
    "\n",
    "    # Get rid of everything we don't need\n",
    "    df.drop(['A..1', u'A.1', u'B.1', u'C.1', u'Country.of.Birth.1', u'Dept.No..1', u'Faculty.No..1',\n",
    "           u'Home.Language.1', u'No..of.Years.in.Uni.at.Time.of.Grant.1', u'Number.of.Successful.Grant.1',\n",
    "           u'Number.of.Unsuccessful.Grant.1', u'Role.1', u'Sponsor.Code', u'With.PHD.1', u'Year.of.Birth.1',\n",
    "           u'SEO.Code.4', u'SEO.Code.5', u'SEO.Code.1', u'SEO.Code.2', u'SEO.Code.3', u'RFCD.Code.1',\n",
    "           u'RFCD.Code.2', u'RFCD.Code.3', u'RFCD.Code.4', u'RFCD.Code.5', 'Grant.Category.Code', u'RFCD.Percentage.1', u'RFCD.Percentage.2', u'RFCD.Percentage.3', u'RFCD.Percentage.4', u'RFCD.Percentage.5', u'SEO.Percentage.1', u'SEO.Percentage.2', u'SEO.Percentage.3', u'SEO.Percentage.4', u'SEO.Percentage.5',], inplace = True, axis = 1)\n",
    "    \n",
    "    df.drop_duplicates(inplace = True)\n",
    "    \n",
    "    #set the index to the 'Grant.Application.ID' - very important that all DFs have the same index in order to merge\n",
    "    df.set_index('Grant.Application.ID', inplace=True)\n",
    "\n",
    "    #Merge all the DF created\n",
    "    finalDf = pd.merge(df, oldest, left_index = True, right_index = True)\n",
    "    finalDf = pd.merge(finalDf, numRole, left_index = True, right_index = True)\n",
    "    finalDf = pd.merge(finalDf, prcAussies, left_index = True, right_index = True)\n",
    "    finalDf = pd.merge(finalDf, numPapers, left_index = True, right_index = True)\n",
    "    finalDf = pd.merge(finalDf, grant_cats, left_index = True, right_index = True)\n",
    "    finalDf = pd.merge(finalDf, rfcds, left_index = True, right_index = True)\n",
    "    finalDf = pd.merge(finalDf, seos, left_index = True, right_index = True)\n",
    "\n",
    "    #imputing ages with median\n",
    "    finalDf['Year.of.Birth.1'] = finalDf['Year.of.Birth.1'].fillna(finalDf['Year.of.Birth.1'].median())\n",
    "\n",
    "    #imputing missing papers with 0\n",
    "    finalDf['A..1']=finalDf['A..1'].fillna(0)\n",
    "    finalDf['A.1']=finalDf['A.1'].fillna(0)\n",
    "    finalDf['B.1']=finalDf['B.1'].fillna(0)\n",
    "    finalDf['C.1']=finalDf['C.1'].fillna(0)\n",
    "\n",
    "    #imputing missing successful and unsuccessful grants with 0\n",
    "    finalDf['Number.of.Successful.Grant.1']=finalDf['Number.of.Successful.Grant.1'].fillna(0)\n",
    "    finalDf['Number.of.Unsuccessful.Grant.1']=finalDf['Number.of.Unsuccessful.Grant.1'].fillna(0)\n",
    "    \n",
    "    # Convert the date column into a usable date format\n",
    "    # datetime.datetime.strptime(date_string, format) returns a datetime according to a format\n",
    "    # .timetuple() generates a tuple from the strptime with all the time information\n",
    "    # time.mktime generates a single time value from the tuple\n",
    "    finalDf['Proc.Start.Date'] = finalDf['Start.date'].apply(lambda x:\n",
    "                          time.mktime(datetime.datetime.strptime(x,'%d/%m/%y').timetuple()))\n",
    "    \n",
    "    return finalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
